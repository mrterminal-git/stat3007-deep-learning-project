{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "731eb1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from typing import Optional, List\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Parses European wholesale electricity price data, allowing filtering\n",
    "    by country and date range.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path=\"./data/european_wholesale_electricity_price_data_daily.csv\"):\n",
    "        \"\"\"\n",
    "        Initializes the parser and loads the data.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): The path to the CSV file.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.data = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        \"\"\"Loads and preprocesses the data from the CSV file.\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(self.file_path)\n",
    "            # Convert 'Date' column to datetime objects\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            # Drop ISO3 Code column\n",
    "            df.drop(columns={'ISO3 Code'}, inplace=True)\n",
    "            # Rename price column for easier access\n",
    "            df.rename(columns={'Price (EUR/MWhe)': 'Price'}, inplace=True)\n",
    "            print(f\"Data loaded successfully from {self.file_path}\")\n",
    "            return df\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found at {self.file_path}\")\n",
    "            return None\n",
    "        except KeyError as e:\n",
    "            print(f\"Error: Expected column '{e}' not found in the CSV.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or processing file: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_data_by_country_and_range(self, time_range:str, country=None):\n",
    "        \"\"\"\n",
    "        Filters the data for a specific country and time range.\n",
    "\n",
    "        Args:\n",
    "            country (str): The name of the country to filter by (e.g., 'Germany').\n",
    "            time_range (str): A string representing the date range in the format\n",
    "                              'YYYY-MM-DD,YYYY-MM-DD'.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: A DataFrame containing the filtered data,\n",
    "                              or None if an error occurs or no data is found.\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"Error: Data not loaded.\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            start_date_str, end_date_str = time_range.split(',')\n",
    "            start_date = pd.to_datetime(start_date_str.strip())\n",
    "            end_date = pd.to_datetime(end_date_str.strip())\n",
    "        except ValueError:\n",
    "            print(\"Error: Invalid time_range format. Please use 'YYYY-MM-DD,YYYY-MM-DD'.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "             print(f\"Error parsing time range: {e}\")\n",
    "             return None\n",
    "\n",
    "        outputData = self.data.copy()\n",
    "        # If a country is specified, filter the data by country, if not use all data\n",
    "        if country is not None:\n",
    "            outputData = self.data[self.data['Country'].str.lower() == country.lower()]\n",
    "\n",
    "        # Filter by date range (inclusive)\n",
    "        filtered_data = outputData[\n",
    "            (outputData['Date'] >= start_date) & (outputData['Date'] <= end_date)\n",
    "        ]\n",
    "\n",
    "        if filtered_data.empty:\n",
    "            print(f\"Warning: No data found for country '{country}' within the range {time_range}.\")\n",
    "            return pd.DataFrame() # Return empty DataFrame\n",
    "\n",
    "        return filtered_data.copy() # Return a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "    def get_all_data(self):\n",
    "        \"\"\"\n",
    "        Returns the entire dataset.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: The entire dataset.\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"Error: Data not loaded.\")\n",
    "            return None\n",
    "        return self.data.copy()\n",
    "\n",
    "    def get_country_list(self):\n",
    "        \"\"\"\n",
    "        Returns a list of unique countries in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of unique country names.\n",
    "        \"\"\"\n",
    "        if self.data is None:\n",
    "            print(\"Error: Data not loaded.\")\n",
    "            return None\n",
    "        return self.data['Country'].unique().tolist()\n",
    "    \n",
    "    def get_price_matrix(\n",
    "        self,\n",
    "        time_range: str,\n",
    "        countries: List[str],\n",
    "        fill_method: Optional[str] = None\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns a price matrix where:\n",
    "        - Rows = dates\n",
    "        - Columns = countries\n",
    "        - Values = daily electricity prices\n",
    "\n",
    "        Parameters:\n",
    "        - time_range (str): e.g. \"2021-05-10,2021-05-16\"\n",
    "        - countries (List[str]): list of country names to include\n",
    "        - fill_method (Optional[str]): 'ffill', 'bfill', or None\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame: index=date, columns=country names, values=prices\n",
    "        \"\"\"\n",
    "        start_date, end_date = time_range.split(\",\")\n",
    "\n",
    "        # Filter the master data once\n",
    "        df = self.data.copy()\n",
    "        df = df[df[\"Country\"].isin(countries)]\n",
    "        df = df[(df[\"Date\"] >= start_date) & (df[\"Date\"] <= end_date)]\n",
    "\n",
    "        # Pivot: index=date, columns=country, values=price\n",
    "        price_matrix = df.pivot(index=\"Date\", columns=\"Country\", values=\"Price\").sort_index()\n",
    "\n",
    "        # Handle missing data\n",
    "        if fill_method:\n",
    "            price_matrix = price_matrix.fillna(method=fill_method)\n",
    "        else:\n",
    "            price_matrix = price_matrix.dropna()\n",
    "\n",
    "        return price_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bce2a3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CointegrationResidualGenerator:\n",
    "    def __init__(self, price_data: pd.DataFrame, risk_free_rate_annual: float = 0.01):\n",
    "        self.price_data = price_data\n",
    "        self.risk_free_rate_daily = risk_free_rate_annual / 252\n",
    "        self.returns = self._compute_excess_returns(price_data)\n",
    "        self.cumulative_returns = self._compute_cumulative_returns(self.returns)\n",
    "        self.asset_residuals = pd.DataFrame(index=self.cumulative_returns.index)\n",
    "        self.betas = {}  # Store betas for each asset\n",
    "\n",
    "    def _compute_excess_returns(self, price_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Computes daily excess log returns.\"\"\"\n",
    "        log_returns = np.log(price_data / price_data.shift(1)).dropna()\n",
    "        excess_returns = log_returns.subtract(self.risk_free_rate_daily)\n",
    "        return excess_returns\n",
    "\n",
    "    def _compute_cumulative_returns(self, returns: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Computes cumulative returns.\"\"\"\n",
    "        cumulative_returns = returns.cumsum()\n",
    "        return cumulative_returns\n",
    "\n",
    "    def compute_all_asset_residuals(self):\n",
    "        \"\"\"Computes residuals for each asset treated as dependent variable.\"\"\"\n",
    "        for target_asset in self.cumulative_returns.columns:\n",
    "            # Set current asset as dependent variable\n",
    "            y = self.cumulative_returns[target_asset].values.reshape(-1, 1)\n",
    "            X = self.cumulative_returns.drop(columns=[target_asset]).values\n",
    "            X_cols = self.cumulative_returns.drop(columns=[target_asset]).columns\n",
    "\n",
    "            # Fit linear regression: y ~ X\n",
    "            model = LinearRegression().fit(X, y)\n",
    "            betas = model.coef_[0]\n",
    "            intercept = model.intercept_[0]\n",
    "\n",
    "            # Predict values and compute residuals for this asset\n",
    "            y_pred = model.predict(X).flatten()\n",
    "            residuals = y.flatten() - y_pred\n",
    "\n",
    "            # Store residuals in DataFrame\n",
    "            self.asset_residuals[target_asset] = residuals\n",
    "            # Store betas for this asset\n",
    "            beta_series = pd.Series(betas, index=X_cols)\n",
    "            beta_series['Intercept'] = intercept\n",
    "            self.betas[target_asset] = beta_series\n",
    "\n",
    "    def get_asset_residuals(self) -> pd.DataFrame:\n",
    "        \"\"\"Returns residuals for all assets.\"\"\"\n",
    "        if self.asset_residuals.empty:\n",
    "            raise ValueError(\"Asset residuals not yet computed.\")\n",
    "        return self.asset_residuals\n",
    "\n",
    "    def get_betas_for_asset(self, asset: str) -> pd.Series:\n",
    "        \"\"\"Returns betas used to form residuals for a specific asset.\"\"\"\n",
    "        if asset not in self.betas:\n",
    "            raise ValueError(f\"Betas for asset '{asset}' not found. Compute residuals first.\")\n",
    "        return self.betas[asset]\n",
    "\n",
    "    def prepare_cnn_input_from_residuals(self, window: int = 30):\n",
    "        \"\"\"\n",
    "        Prepares CNN input data by creating rolling cumulative residuals.\n",
    "        \n",
    "        Returns:\n",
    "        - 3D numpy array: [samples, window, assets]\n",
    "        \"\"\"\n",
    "        if self.asset_residuals.empty:\n",
    "            raise ValueError(\"Asset residuals not yet computed.\")\n",
    "\n",
    "        cnn_input_list = []\n",
    "\n",
    "        for start_idx in range(len(self.asset_residuals) - window + 1):\n",
    "            # Slice window of residuals\n",
    "            window_residuals = self.asset_residuals.iloc[start_idx:start_idx + window]\n",
    "            # Cumulative sum within the window\n",
    "            cumulative_window = window_residuals.cumsum()\n",
    "            # Store the result\n",
    "            cnn_input_list.append(cumulative_window.values)\n",
    "\n",
    "        # Convert to 3D numpy array: [samples, window, assets]\n",
    "        cnn_input_array = np.array(cnn_input_list)\n",
    "        return cnn_input_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b1826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_length, num_features, num_filters= 8, num_classes=2, filter_size=2):\n",
    "        \"\"\"\n",
    "        Initialize the CNN model based on the equations in the paper.\n",
    "        \n",
    "        Args:\n",
    "            input_length (int): Length of the input sequence (L in the equations)\n",
    "            num_features (int): Number of features per time step\n",
    "            num_classes (int): Number of output classes\n",
    "        \"\"\"\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.num_filters = num_filters  # Number of filters (D = 8 according to equation)\n",
    "        self.filter_size = filter_size  # Filter size (filter_size = 2 according to equation)\n",
    "        \n",
    "        # First convolutional layer (Equation 3)\n",
    "        # Input shape: [batch_size, num_features, input_length]\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=num_features,\n",
    "            out_channels=self.num_filters,\n",
    "            kernel_size=self.filter_size,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "        \n",
    "        # Second convolutional layer (Equation 4)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=self.num_filters,\n",
    "            out_channels=self.num_filters,\n",
    "            kernel_size=self.filter_size,\n",
    "            stride=1,\n",
    "            padding=0\n",
    "        )\n",
    "        \n",
    "        # Calculate output sizes after convolutions\n",
    "        L_after_conv1 = input_length - self.filter_size + 1\n",
    "        L_after_conv2 = L_after_conv1 - self.filter_size + 1\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(self.num_filters * L_after_conv2, num_classes)\n",
    "        \n",
    "        # Activation\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape [batch_size, num_features, input_length]\n",
    "                             Represents the x_i(t) vector in Equation 2\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Output predictions\n",
    "        \"\"\"\n",
    "        # Store original input for skip connection (Equation 5)\n",
    "        x_original = x\n",
    "        \n",
    "        # First convolutional layer (Equation 3)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        \n",
    "        # Second convolutional layer (Equation 4)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        \n",
    "        # Skip connection (Equation 5)\n",
    "        # Need to adjust dimensions for skip connection\n",
    "        # Cut or pad x_original to match x dimensions\n",
    "        if x_original.shape[2] > x.shape[2]:\n",
    "            # If original is longer, cut it\n",
    "            diff = x_original.shape[2] - x.shape[2]\n",
    "            x_skip = x_original[:, :, diff:]\n",
    "        else:\n",
    "            # If original is shorter, this would require padding\n",
    "            # For simplicity, we'll just use the original shape\n",
    "            x_skip = x_original\n",
    "        \n",
    "        # Apply the skip connection if dimensions match\n",
    "        if x.shape == x_skip.shape:\n",
    "            x = x + x_skip\n",
    "        \n",
    "        # Flatten and pass through fully connected layer\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_parameters(self):\n",
    "        return self.parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e620c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # building blocks for neural networks\n",
    "import torch.nn.functional as F # access to functions like ReLU, sigmoid, etc.\n",
    "\n",
    "class FNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=32, output_dim=31):\n",
    "        \"\"\"\n",
    "        Initialize the Feedforward Neural Network.\n",
    "        \n",
    "        Args:\n",
    "            input_dim (int): Input dimension (matches CNN output)\n",
    "            hidden_dim (int): Hidden layer dimension\n",
    "            output_dim (int): Number of output weights (one per country)\n",
    "        \"\"\"\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape [batch_size, input_dim]\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape [batch_size, output_dim]\n",
    "        \"\"\"\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        w_eps = self.out(x)  # Shape: [batch_size, output_dim]\n",
    "        return w_eps\n",
    "    \n",
    "# equation (11) from project framework\n",
    "def soft_normalize(weights):\n",
    "    \"\"\"\n",
    "    Normalize allocation weights using L1 norm (sum of absolute values).\n",
    "    weights: Tensor of shape [batch_size, 1]\n",
    "    Returns: Normalized weights of shape [batch_size, 1]\n",
    "    \"\"\"\n",
    "    l1_norm = torch.sum(torch.abs(weights), dim=0, keepdim=True) + 1e-8 # avoid division by zero\n",
    "    normalized_weights = weights / l1_norm\n",
    "    return normalized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8483f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BacktestSharpeEvaluator:\n",
    "    def __init__(self):\n",
    "        self.portfolio_returns = []\n",
    "\n",
    "    def add_return(self, r: float):\n",
    "        \"\"\"Add a single next-day portfolio return.\"\"\"\n",
    "        self.portfolio_returns.append(r)\n",
    "\n",
    "    def add_returns(self, returns: list):\n",
    "        \"\"\"Add a list of next-day portfolio returns.\"\"\"\n",
    "        self.portfolio_returns.extend(returns)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the stored returns.\"\"\"\n",
    "        self.portfolio_returns = []\n",
    "\n",
    "    def calculate_sharpe(self, returns=None, risk_free_rate=0.0):\n",
    "        \"\"\"\n",
    "        Calculate Sharpe Ratio from stored or passed-in returns.\n",
    "        Sharpe Ratio = (mean - risk-free) / std deviation\n",
    "        \"\"\"\n",
    "        r = self.portfolio_returns if returns is None else returns\n",
    "        r = np.array(r)\n",
    "        if len(r) == 0 or np.std(r) == 0:\n",
    "            return np.nan\n",
    "        excess_returns = r - risk_free_rate\n",
    "        return np.mean(excess_returns) / np.std(excess_returns)\n",
    "\n",
    "    def normalize_weights_l1(self, raw_weights, phi=None):\n",
    "        \"\"\"\n",
    "        Normalize raw weights using Ordo√±ez's method:\n",
    "        w_normalized = (w_raw^T * phi) / ||w_raw^T * phi||_1\n",
    "\n",
    "        Parameters:\n",
    "            raw_weights: numpy array of shape (n_assets,)\n",
    "            phi: optional transformation matrix (e.g., identity or mapping from factor to asset space)\n",
    "\n",
    "        Returns:\n",
    "            L1-normalized weights: numpy array of shape (n_assets,)\n",
    "        \"\"\"\n",
    "        if phi is None:\n",
    "            phi = np.eye(len(raw_weights))  # default to identity if no mapping provided\n",
    "        raw = raw_weights.T @ phi\n",
    "        norm = np.sum(np.abs(raw))\n",
    "        if norm == 0:\n",
    "            return np.zeros_like(raw)\n",
    "        return raw / norm\n",
    "\n",
    "    def compute_portfolio_return(self, raw_weights, next_day_returns, phi=None):\n",
    "        \"\"\"\n",
    "        Normalize weights, compute and store the next-day portfolio return.\n",
    "\n",
    "        Parameters:\n",
    "            raw_weights: numpy array of shape (n_assets,)\n",
    "            next_day_returns: numpy array of shape (n_assets,)\n",
    "            phi: optional transformation matrix\n",
    "\n",
    "        Returns:\n",
    "            Computed return (float)\n",
    "        \"\"\"\n",
    "        w = self.normalize_weights_l1(raw_weights, phi)\n",
    "        r = float(np.dot(w, next_day_returns))\n",
    "        self.add_return(r)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e616df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio_loss(returns, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    Custom loss function to maximize the Sharpe Ratio.\n",
    "    Args:\n",
    "        returns (torch.Tensor): Predicted returns\n",
    "        risk_free_rate (float): Risk-free rate for Sharpe calculation\n",
    "    Returns:\n",
    "        torch.Tensor: Negative Sharpe Ratio (to minimize)\n",
    "    \"\"\"\n",
    "    excess_returns = returns - risk_free_rate\n",
    "    mean_excess = torch.mean(excess_returns)\n",
    "    std_excess = torch.std(excess_returns, unbiased=False) + 1e-6  # epsilon for stability\n",
    "    sharpe_ratio = mean_excess / std_excess\n",
    "    return -sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c080b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "class PortfolioOptimizer:\n",
    "    \"\"\"\n",
    "    A class to train and evaluate a CNN+FNN model for portfolio optimization,\n",
    "    generating weights to maximize the Sharpe ratio based on electricity price residuals.\n",
    "    \"\"\"\n",
    "    def __init__(self, cnn_input_array: np.array, next_day_returns: pd.DataFrame, device=None, num_filters=8, filter_size=2, hidden_dim=32,\n",
    "                 lr=0.001, num_epochs=1000, batch_size=32):\n",
    "        \"\"\"\n",
    "        Initialize the portfolio optimizer with input data and hyperparameters.\n",
    "\n",
    "        Args:\n",
    "            cnn_input_array (np.ndarray): Input residuals with shape [samples, num_countries, window_size].\n",
    "            next_day_returns (pd.DataFrame): Next-day returns with shape [samples, num_countries].\n",
    "            device (torch.device, optional): Device for computation (cuda, mps, or cpu). Defaults to auto-detection.\n",
    "            num_filters (int): Number of CNN filters.\n",
    "            filter_size (int): Size of CNN convolutional filters.\n",
    "            hidden_dim (int): Hidden dimension for CNN output and FNN layers.\n",
    "            lr (float): Learning rate for the optimizer.\n",
    "            num_epochs (int): Number of training epochs.\n",
    "            batch_size (int): Batch size for training.\n",
    "        \"\"\"\n",
    "        # Set device (GPU, MPS, or CPU)\n",
    "        if device is None:\n",
    "            if torch.cuda.is_available():\n",
    "                device = torch.device(\"cuda\")\n",
    "            elif torch.backends.mps.is_available():\n",
    "                device = torch.device(\"mps\")\n",
    "            else:\n",
    "                device = torch.device(\"cpu\")\n",
    "        self.device = device\n",
    "\n",
    "        # Data dimensions\n",
    "        self.num_countries = cnn_input_array.shape[1]  # Number of countries (31)\n",
    "        self.window_size = cnn_input_array.shape[2]    # Window size for residuals (30)\n",
    "        self.num_samples = cnn_input_array.shape[0]    # Number of samples (329, or the number of days)\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lr = lr\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Convert input data to PyTorch tensors\n",
    "        self.cnn_input_tensor = torch.FloatTensor(cnn_input_array).to(self.device)\n",
    "        self.next_day_returns_tensor = torch.FloatTensor(next_day_returns.values).to(self.device)\n",
    "\n",
    "        # Initialize models\n",
    "        self.cnn_model = self._initialize_cnn()\n",
    "        self.fnn_model = self._initialize_fnn()\n",
    "\n",
    "        # Initialize optimizer\n",
    "        self.optimizer = optim.Adam(\n",
    "            list(self.cnn_model.parameters()) + list(self.fnn_model.parameters()),\n",
    "            lr=self.lr\n",
    "        )\n",
    "\n",
    "        # Initialize evaluator for Sharpe ratio calculation\n",
    "        self.evaluator = BacktestSharpeEvaluator()\n",
    "\n",
    "    def _initialize_cnn(self):\n",
    "        \"\"\"\n",
    "        Initialize the CNN model.\n",
    "\n",
    "        Returns:\n",
    "            CNN: Initialized CNN model on the specified device.\n",
    "        \"\"\"\n",
    "        # Calculate output sizes after convolutions\n",
    "        L_after_conv1 = self.window_size - self.filter_size + 1  # e.g., 30 - 2 + 1 = 29\n",
    "        L_after_conv2 = L_after_conv1 - self.filter_size + 1    # e.g., 29 - 2 + 1 = 28\n",
    "\n",
    "        cnn = CNN(\n",
    "            input_length=self.window_size,\n",
    "            num_features=self.num_countries,\n",
    "            num_filters=self.num_filters,\n",
    "            num_classes=self.hidden_dim,  # Output matches FNN input dimension\n",
    "            filter_size=self.filter_size\n",
    "        ).to(self.device)\n",
    "        return cnn\n",
    "\n",
    "    def _initialize_fnn(self):\n",
    "        \"\"\"\n",
    "        Initialize the FNN model.\n",
    "\n",
    "        Returns:\n",
    "            FNN: Initialized FNN model on the specified device.\n",
    "        \"\"\"\n",
    "        fnn = FNN(\n",
    "            input_dim=self.hidden_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            output_dim=self.num_countries  # One weight per country\n",
    "        ).to(self.device)\n",
    "        return fnn\n",
    "\n",
    "    def soft_normalize(self, weights):\n",
    "        \"\"\"\n",
    "        Normalize weights using L1 norm (sum of absolute values = 1).\n",
    "\n",
    "        Args:\n",
    "            weights (torch.Tensor): Raw weights with shape [batch_size, num_countries].\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Normalized weights with shape [batch_size, num_countries].\n",
    "        \"\"\"\n",
    "        l1_norm = torch.sum(torch.abs(weights), dim=1, keepdim=True) + 1e-8  # Avoid division by zero\n",
    "        normalized_weights = weights / l1_norm\n",
    "        return normalized_weights\n",
    "\n",
    "    def sharpe_ratio_loss(self, returns, risk_free_rate=0.0):\n",
    "        \"\"\"\n",
    "        Compute negative Sharpe ratio as loss for optimization.\n",
    "\n",
    "        Args:\n",
    "            returns (torch.Tensor): Portfolio returns with shape [batch_size].\n",
    "            risk_free_rate (float): Risk-free rate (default: 0.0).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Negative Sharpe ratio (scalar).\n",
    "        \"\"\"\n",
    "        excess_returns = returns - risk_free_rate\n",
    "        mean_excess = torch.mean(excess_returns)\n",
    "        std_excess = torch.std(excess_returns, unbiased=False) + 1e-5  # Avoid division by zero\n",
    "        sharpe_ratio = mean_excess / std_excess\n",
    "        return -sharpe_ratio\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the CNN+FNN model to maximize the Sharpe ratio.\n",
    "\n",
    "        Returns:\n",
    "            list: Portfolio returns from the final evaluation.\n",
    "        \"\"\"\n",
    "        for epoch in range(self.num_epochs):\n",
    "            # Set models to training mode\n",
    "            self.cnn_model.train()\n",
    "            self.fnn_model.train()\n",
    "\n",
    "            # Process data in batches\n",
    "            for batch_idx in range(0, len(self.cnn_input_tensor), self.batch_size):\n",
    "                # Extract batch\n",
    "                batch_end = min(batch_idx + self.batch_size, len(self.cnn_input_tensor))\n",
    "                batch_inputs = self.cnn_input_tensor[batch_idx:batch_end]  # Shape: [batch_size, num_countries, window_size]\n",
    "                batch_returns = self.next_day_returns_tensor[batch_idx:batch_end]  # Shape: [batch_size, num_countries]\n",
    "\n",
    "                # Zero gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass: CNN processes residuals\n",
    "                cnn_output = self.cnn_model(batch_inputs)  # Shape: [batch_size, hidden_dim]\n",
    "\n",
    "                # Forward pass: FNN generates weights\n",
    "                weights = self.fnn_model(cnn_output)  # Shape: [batch_size, num_countries]\n",
    "\n",
    "                # Normalize weights to sum to 1 (L1 norm)\n",
    "                normalized_weights = self.soft_normalize(weights)  # Shape: [batch_size, num_countries]\n",
    "\n",
    "                # Compute portfolio returns (dot product of weights and returns)\n",
    "                portfolio_returns = torch.sum(normalized_weights * batch_returns, dim=1)  # Shape: [batch_size]\n",
    "\n",
    "                # Compute loss (negative Sharpe ratio)\n",
    "                loss = self.sharpe_ratio_loss(portfolio_returns)\n",
    "\n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                # Evaluate Sharpe ratio for every 10th epoch\n",
    "                sharpe = self._evaluate_epoch()\n",
    "                print(f\"Epoch {epoch}, Sharpe Ratio: {sharpe:.4f}\")\n",
    "\n",
    "        # Perform final evaluation\n",
    "        final_sharpe, portfolio_returns = self.evaluate_final()\n",
    "        print(f\"\\nFinal Sharpe Ratio: {final_sharpe:.4f}\")\n",
    "\n",
    "        return portfolio_returns\n",
    "\n",
    "    def _evaluate_epoch(self):\n",
    "        \"\"\"\n",
    "        Evaluate the model for one epoch, computing the Sharpe ratio.\n",
    "\n",
    "        Returns:\n",
    "            float: Sharpe ratio for the epoch.\n",
    "        \"\"\"\n",
    "        self.evaluator.reset()\n",
    "        self.cnn_model.eval()\n",
    "        self.fnn_model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(self.cnn_input_tensor), self.batch_size):\n",
    "                batch_end = min(i + self.batch_size, len(self.cnn_input_tensor))\n",
    "                batch_inputs = self.cnn_input_tensor[i:batch_end]\n",
    "                batch_returns = self.next_day_returns_tensor[i:batch_end]\n",
    "\n",
    "                # Forward pass\n",
    "                cnn_output = self.cnn_model(batch_inputs)\n",
    "                weights = self.fnn_model(cnn_output)\n",
    "                normalized_weights = self.soft_normalize(weights)\n",
    "\n",
    "                # Compute portfolio returns\n",
    "                portfolio_returns = torch.sum(normalized_weights * batch_returns, dim=1)\n",
    "                portfolio_returns_np = portfolio_returns.cpu().numpy()\n",
    "\n",
    "                # Store returns in evaluator\n",
    "                for return_val in portfolio_returns_np:\n",
    "                    self.evaluator.add_return(return_val)\n",
    "\n",
    "        return self.evaluator.calculate_sharpe()\n",
    "\n",
    "    def evaluate_final(self):\n",
    "        \"\"\"\n",
    "        Perform final evaluation on all samples.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (final Sharpe ratio, list of portfolio returns).\n",
    "        \"\"\"\n",
    "        self.evaluator.reset()\n",
    "        self.cnn_model.eval()\n",
    "        self.fnn_model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(self.cnn_input_tensor)):\n",
    "                inputs = self.cnn_input_tensor[i:i+1]  # Shape: [1, num_countries, window_size]\n",
    "                returns = self.next_day_returns_tensor[i:i+1]  # Shape: [1, num_countries]\n",
    "\n",
    "                # Forward pass\n",
    "                cnn_output = self.cnn_model(inputs)\n",
    "                weights = self.fnn_model(cnn_output)\n",
    "                normalized_weights = self.soft_normalize(weights)\n",
    "\n",
    "                # Compute portfolio return\n",
    "                portfolio_return = torch.sum(normalized_weights * returns, dim=1).item()\n",
    "                self.evaluator.add_return(portfolio_return)\n",
    "\n",
    "        final_sharpe = self.evaluator.calculate_sharpe()\n",
    "        return final_sharpe, self.evaluator.portfolio_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "83b2a072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from ./data/european_wholesale_electricity_price_data_daily.csv\n",
      "\n",
      "--- List of Countries ---\n",
      "['Austria', 'Belgium', 'Czechia', 'Denmark', 'Estonia', 'Finland', 'France', 'Germany', 'Greece', 'Hungary', 'Italy', 'Latvia', 'Lithuania', 'Luxembourg', 'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania', 'Slovakia', 'Slovenia', 'Spain', 'Sweden', 'Switzerland', 'United Kingdom', 'Bulgaria', 'Serbia', 'Croatia', 'Montenegro', 'North Macedonia', 'Ireland']\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Epoch 0, Sharpe Ratio: 0.0005\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_l/8ljm4_2n0cl02xgf0_pbjrtw0000gn/T/ipykernel_25650/797593302.py:142: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  price_matrix = price_matrix.fillna(method=fill_method)\n",
      "/Users/filip/stat7007/project/venv/lib/python3.12/site-packages/pandas/core/internals/blocks.py:393: RuntimeWarning: invalid value encountered in log\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Epoch 10, Sharpe Ratio: 0.0348\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Epoch 20, Sharpe Ratio: 0.0520\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Epoch 30, Sharpe Ratio: 0.0615\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Epoch 40, Sharpe Ratio: 0.0727\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Epoch 50, Sharpe Ratio: 0.0938\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Epoch 60, Sharpe Ratio: 0.1118\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Epoch 70, Sharpe Ratio: 0.1329\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Epoch 80, Sharpe Ratio: 0.1586\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Epoch 90, Sharpe Ratio: 0.1756\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([329, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "Normalized weights: torch.Size([1, 31])\n",
      "\n",
      "Final Sharpe Ratio: 0.1653\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# MAIN FUNCTION\n",
    "### -------------- PARSING DATA -------------- ###\n",
    "parser = DataLoader()\n",
    "\n",
    "# Get list of countries\n",
    "print(\"\\n--- List of Countries ---\")\n",
    "all_countries_list = parser.get_country_list()\n",
    "print(all_countries_list)\n",
    "\n",
    "# Get daily price matrix for all countries for the entire year 2021\n",
    "price_matrix = parser.get_price_matrix(\n",
    "    time_range=\"2021-01-01,2021-12-31\",\n",
    "    countries=all_countries_list,\n",
    "    fill_method=\"ffill\"\n",
    ")\n",
    "\n",
    "# Get the raw daily returns for the price matrix\n",
    "returns = price_matrix.pct_change().dropna()\n",
    "\n",
    "\n",
    "\n",
    "### -------------- COINTEGRATION RESIDUALS -------------- ###\n",
    "# Create an instance of the CointegrationResidualGenerator\n",
    "residual_generator = CointegrationResidualGenerator(price_matrix)\n",
    "\n",
    "residual_generator.compute_all_asset_residuals()\n",
    "\n",
    "# Get residuals\n",
    "asset_residuals = residual_generator.get_asset_residuals()\n",
    "\n",
    "# Get the input for CNN\n",
    "# cnn_input contains a set of 329 data samples, each sample represents 30-day cumulative residuals for the 31 countries\n",
    "cumulative_residual_window = 30\n",
    "cnn_input = residual_generator.prepare_cnn_input_from_residuals(window=cumulative_residual_window)\n",
    "\n",
    "# Get the start index of the first 30-day cumulative residuals in the returns DataFrame\n",
    "start_idx_in_returns = returns.index.get_loc(asset_residuals.index[0])\n",
    "num_samples = len(asset_residuals) - cumulative_residual_window + 1\n",
    "next_day_indices = [start_idx_in_returns + i + cumulative_residual_window for i in range(num_samples)]\n",
    "\n",
    "# Get the next-day returns for the corresponding indices\n",
    "# The next-day returns are the returns for the day after the last day of each 30-day window\n",
    "# For example, if the first 30-day window ends on index 0, the next day return is at index 1\n",
    "# If the second 30-day window ends on index 1, the next day return is at index 2, and so on.\n",
    "next_day_returns = returns.iloc[next_day_indices]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### -------------- FEED THE 30-DAY CUMULATIVE RESIDUALS OF EVERY COUNTRY TO CNN+FNN -------------- ###\n",
    "# Transform cnn_input to be compatible with the CNN input shape\n",
    "cnn_input_array = cnn_input.transpose(0, 2, 1) # [samples, features, window]\n",
    "\n",
    "# FILIP'S SECTION: CNN+FNN\n",
    "# Hey Filip, this is the section where you can add your code to train the CNN+FNN model.\n",
    "# cnn_input_array essentially contains 329 training data points, each data point is 30-day cumulative residuals for the 31 countries.\n",
    "# So, for one \"data point\" you would feed the set of 30-day cumulative residuals for every country to the CNN+FNN model.\n",
    "# One data point should result in a set of weights for each of the 31 countries.\n",
    "# Each set of weights is used to calculate one next-day portfolio return.\n",
    "# Repeat this for all 329 data points to get a set of 329 portfolio returns.\n",
    "# You can then use these portfolio returns to calculate the Sharpe ratio\n",
    "# Optimize the CNN+FFN to maximize the Sharpe ratio.\n",
    "\n",
    "# Set the device to GPU if available, otherwise MPS (for Mac silicon) or CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "torch.manual_seed(1)  # For reproducibility\n",
    "\n",
    "# Create the PortfolioOptimizer instance and train the model\n",
    "# NOTE: We need to have some validation data to evaluate the model performance\n",
    "# otherwise we will be overfitting the model to the training data\n",
    "optimizer = PortfolioOptimizer(cnn_input_array, next_day_returns, batch_size=1000, num_epochs=100)\n",
    "portfolio_returns = optimizer.train()\n",
    "\n",
    "### -------------- GET THE WEIGHTS OUTPUTTED FROM CNN+FNN -------------- ###\n",
    "# Initializing the Sharpe ratio evaluator\n",
    "#evaluator = BacktestSharpeEvaluator()\n",
    "\n",
    "# Get the weight outputted from the CNN+FNN model\n",
    "# One weight for each country\n",
    "#weights = np.array([]) # CHANGE THIS TO THE ACTUAL WEIGHTS OUTPUTTED FROM THE CNN+FNN MODEL\n",
    "\n",
    "# Normalize the weights using L1 normalization\n",
    "# This is done to ensure that the portfolio is dollar-neutral\n",
    "#normalized_weights = evaluator.normalize_weights_l1(weights)\n",
    "\n",
    "# Multiply the normalized weights (vector) with the next-day returns (vector) to get the portfolio return\n",
    "#next_day_portfolio_return = evaluator.compute_portfolio_return(normalized_weights, next_day_returns.iloc[0].values)\n",
    "\n",
    "# Store the next day portfolio return \n",
    "#evaluator.add_return(next_day_portfolio_return)\n",
    "\n",
    "# Repeat the above step for all 329 data points, adding the portfolio returns to the evaluator for each data point\n",
    "\n",
    "# Once all portfolio returns are calculated, you can calculate the Sharpe ratio\n",
    "\n",
    "# Train the model to optimize the Sharpe Ratio\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
